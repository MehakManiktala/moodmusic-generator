{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import nltk\n",
    "import nbimporter\n",
    "from get_classifiers import nb_classify, svm_classify, process_data, ens_classify\n",
    "import threading\n",
    "import random\n",
    "\n",
    "\n",
    "index = random.randint(1,2000000)\n",
    "SVM = 1\n",
    "NB = 2\n",
    "ENS = 3\n",
    "BINARY = 2\n",
    "MULTICLASS = 5\n",
    "\n",
    "model = NB\n",
    "no_of_classes = MULTICLASS\n",
    "\n",
    "def get_emotion(value, no_of_classes):\n",
    "    if no_of_classes == 2:\n",
    "        unique_labels = [\"Positive\",\"Negative\"]\n",
    "    else:\n",
    "        unique_labels = [\"Happy\",\"Surprised\",\"Angry\",\"Fear\",\"Sad\"]\n",
    "    return unique_labels[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You came early into this world. You were such a wee thing, so frail, so fragile.... I feared you wouldn't make it. But your knew. He always said you'd be the strongest of them all. And he was right.\n"
     ]
    }
   ],
   "source": [
    "aesop1 = \"A DOG used to run up quietly to the heels of everyone he met, and to bite them without notice. His master suspended a bell about his neck so that the Dog might give notice of his presence wherever he went. Thinking it a mark of distinction, the Dog grew proud of his bell and went tinkling it all over the marketplace. One day an old hound said to him: Why do you make such an exhibition of yourself? That bell that you carry is not, believe me, any order of merit, but on the contrary a mark of disgrace, a public notice to all men to avoid you as an ill mannered dog. Notoriety is often mistaken for fame\"\n",
    "aesop2 = \"A RIVER carried down in its stream two Pots, one made of earthenware and the other of brass. The Earthen Pot said to the Brass Pot, 'Pray keep at a distance and do not come near me, for if you touch me ever so slightly, I shall be broken in pieces, and besides, I by no means wish to come near you.' Equals make the best friends\"\n",
    "gameAssassin = \"I have lived my life as best I could, not knowing its purpose, but drawn forward like a moth to a distant moon. And here, at last I discover a strange truth. That I am only a conduit for a message that eludes my understanding. Who are we, who have been so blessed to share our stories like this? To speak across centuries?\"\n",
    "#--Ezio at the end of Assassinâ€™s Creed Revelations\n",
    "worstPanda = \"Your mind is like this water, my friend. When it gets agitated, it becomes difficult to see. But if you allow it to settle, the answer becomes clear.\"\n",
    "input_text = \"You came early into this world. You were such a wee thing, so frail, so fragile.... I feared you wouldn't make it. But your knew. He always said you'd be the strongest of them all. And he was right.\"\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You came early into this world. #Happy', 'You were such a wee thing, so frail, so fragile.... #Happy', \"I feared you wouldn't make it. #Fear\", 'But your knew. #Fear', \"He always said you'd be the strongest of them all. #Fear\", 'And he was right. #Fear']\n"
     ]
    }
   ],
   "source": [
    "input_sent = sent_tokenize(input_text)\n",
    "input_sentences = pd.DataFrame(data=input_sent)\n",
    "input_sentences = process_data(input_sentences[0])\n",
    "\n",
    "if model == NB:\n",
    "    pred = nb_classify(input_sentences, no_of_classes)\n",
    "elif model == SVM:\n",
    "    pred = svm_classify(input_sentences, no_of_classes)\n",
    "else:\n",
    "    pred = ens_classify(input_sentences, no_of_classes)\n",
    "\n",
    "output = []\n",
    "for i, sentence in enumerate(input_sent):\n",
    "    output_line = sentence + \" #\"+get_emotion(int(pred[i]),no_of_classes)\n",
    "    output.append(output_line)\n",
    "\n",
    "print(output)\n",
    "\n",
    "import os\n",
    "sentenceDir = \"../inputsentences\"\n",
    "\n",
    "import os\n",
    "filename = os.path.join(sentenceDir, \"sentence\"+str(index)+\".moodsentence\")\n",
    "index += 1\n",
    "f= open(filename,'w+')\n",
    "for sentence in output:\n",
    "    f.write(sentence+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
