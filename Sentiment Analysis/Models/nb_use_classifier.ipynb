{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"World is huge. It's full of wonders. Today is going to be an exciting day. The day started off nice, but it got depressing by the afternoon. As the evening came, I realised how I forgot to text my boyfriend. I called him up and that made me feel better. I slept with a smile on my face.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0                                     world is huge.\n",
      "1                              it's full of wonders.\n",
      "2              today is going to be an exciting day.\n",
      "3  the day started off nice, but it got depressin...\n",
      "4  as the evening came, i realised how i forgot t...\n",
      "5      i called him up and that made me feel better.\n",
      "6                   i slept with a smile on my face.\n"
     ]
    }
   ],
   "source": [
    "input_sentences = sent_tokenize(input_text.lower())\n",
    "input_sentences = pd.DataFrame(data=input_sentences)\n",
    "print(input_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if emo == 2: \n",
    "    dataset_path = '../Data/Datasets/Binary Classification/'\n",
    "else:\n",
    "    dataset_path = '../Data/Datasets/Multiclass Classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(dataset_path+'nb_classifier.pkl')\n",
    "word_features = joblib.load('../Data/nb_word_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_features(sentence):\n",
    "    return {i:(i in sentence) for i in word_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.]\n",
      " [3.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]]\n",
      "2: 0.005752\n",
      "3: 0.008023\n",
      "0: 0.962481\n",
      "1: 0.000000\n",
      "4: 0.023743\n"
     ]
    }
   ],
   "source": [
    "pred = np.zeros((len(input_sentences),1))\n",
    "pred_prob = np.zeros((len(input_sentences),1))\n",
    "for idx,line in enumerate(input_sentences[0]):\n",
    "    words = nltk.word_tokenize(line)\n",
    "    featured_item = (convert_features(words))\n",
    "    pred[idx]  = int(clf.classify(featured_item))\n",
    "    pred_prob = clf.prob_classify(featured_item)\n",
    "\n",
    "                \n",
    "print(pred)\n",
    "\n",
    "for label in pred_prob.samples():\n",
    "    print(\"%s: %f\" % (label, pred_prob.prob(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(value):\n",
    "    if emo ==2:\n",
    "        unique_labels = [\"Positive\",\"Negative\"]\n",
    "    else:\n",
    "        unique_labels = [\"Happy\",\"Surprise\",\"Anger\",\"Fear\",\"Sadness\"]\n",
    "    return unique_labels[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i, sentence in enumerate(input_sentences[0]):\n",
    "    output_line = sentence + '. #' + get_emotion(int(pred[i]))\n",
    "    output.append(output_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['world is huge.. #Fear', \"it's full of wonders.. #Fear\", 'today is going to be an exciting day.. #Happy', 'the day started off nice, but it got depressing by the afternoon.. #Happy', 'as the evening came, i realised how i forgot to text my boyfriend.. #Anger', 'i called him up and that made me feel better.. #Anger', 'i slept with a smile on my face.. #Happy']\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehak\\Documents\\RNN\\inputsentences\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "import os\n",
    "sentenceDir = \"../inputsentences\"\n",
    "print(sentenceDir)\n",
    "\n",
    "import os\n",
    "for sentence in output:\n",
    "    filename = os.path.join(sentenceDir, \"sentence\"+str(index)+\".moodsentence\")\n",
    "    index += 1\n",
    "    f= open(filename,'w+')\n",
    "    f.write(sentence)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
