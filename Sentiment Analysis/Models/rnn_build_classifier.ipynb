{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehak\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, GRU, Bidirectional, MaxPooling1D, Conv1D, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform, he_uniform, zeros\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import metrics\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_textFile(filePath):\n",
    "    ds_text = []\n",
    "    with open(filePath,'rb') as f:\n",
    "        for idx,ln in enumerate(f):\n",
    "            decoded=False\n",
    "            line=''\n",
    "            for cp in ('cp1252', 'cp850','utf-8','utf8'):\n",
    "                try:\n",
    "                    line = ln.decode(cp)\n",
    "                    decoded=True\n",
    "                    break\n",
    "                except UnicodeDecodeError:\n",
    "                    pass\n",
    "            if decoded:\n",
    "                ds_text.insert(idx, line.rstrip())\n",
    "    return ds_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if emo == 2: \n",
    "    dataset_path = '../Data/Datasets/Binary Classification/'\n",
    "else:\n",
    "    dataset_path = '../Data/Datasets/Multiclass Classification/'\n",
    "    \n",
    "train_ds = pd.read_csv(dataset_path+'train.csv', sep=\",\", header=None,index_col = False)\n",
    "test_ds = pd.read_csv(dataset_path+'test.csv', sep=\",\", header=None,index_col = False)\n",
    "\n",
    "x_train = train_ds[0]\n",
    "y_train = train_ds[1]\n",
    "\n",
    "x_test = test_ds[0]\n",
    "y_test = test_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "maxLen = len(max(x_train, key=len).split())\n",
    "print(maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(y):\n",
    "    one_hot_temp_array = array(y)\n",
    "    one_hot_array = to_categorical(one_hot_temp_array)\n",
    "    return one_hot_array\n",
    "# invert encoding\n",
    "#inverted = argmax(encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load glove diembedding_dict = dict()\n",
    "embedding_dict = joblib.load('../Data/rnn_embedding_dict.pkl')\n",
    "glove_words = joblib.load('../Data/rnn_glove_words.pkl')\n",
    "number_to_word = glove_words\n",
    "word_to_number = dict((word,idx) for idx,word in enumerate(glove_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(input_x, word_to_number, max_len):\n",
    "    m = input_x.shape[0]\n",
    "    x_indices = np.zeros((m,max_len))\n",
    "\n",
    "    for i in range(m):\n",
    "        word_list =input_x.iloc[i][0].lower().split()\n",
    "        for idx,word in enumerate(word_list):\n",
    "            if (idx ==32):\n",
    "                continue\n",
    "            x_indices[i, idx] = word_to_number[word]\n",
    "    return x_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_layer(embedding_dict, word_to_number):\n",
    "    \n",
    "    emb_shape = embedding_dict[\"cucumber\"].shape[0]\n",
    "    total_words = len(word_to_number) + 1\n",
    "    \n",
    "    emb_matrix = np.zeros((total_words,emb_shape))\n",
    "    \n",
    "    for word,idx in word_to_number.items():\n",
    "        emb_matrix[idx, :] = embedding_dict[word]\n",
    "\n",
    "    embedding_layer = Embedding(total_words, emb_shape, trainable = True)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senti_model(input_shape,embedding_dict, word_to_number):\n",
    "    #np.random.seed(1)\n",
    "    sentence_indices = Input(shape = input_shape, dtype = np.int32)\n",
    "    embedding_layer = get_embedding_layer(embedding_dict, word_to_number)\n",
    "    \n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    X = Dropout(0.4)(embeddings)\n",
    "    X = Bidirectional(GRU(64,return_sequences=True))(X)\n",
    "    X = Dense(16, activation='elu')(X)\n",
    "    X = Bidirectional(GRU(64,return_sequences=False))(X)\n",
    "    X = Dense(64, activation='elu')(X)\n",
    "    X = Dense(emo, activation='softmax', name='fc')(X)\n",
    "\n",
    "\n",
    "\n",
    "    #X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs = sentence_indices, outputs = X, name='sentiment')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 28, 50)            20000000  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 28, 128)           44160     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 28, 16)            2064      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               31104     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 20,085,909\n",
      "Trainable params: 20,085,909\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = senti_model((maxLen,), embedding_dict, word_to_number)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = Adam(lr=0.0001)\n",
    "adadelta = Adadelta(lr=1.00, rho=0.95, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adadelta, metrics=[metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2809, 5)\n"
     ]
    }
   ],
   "source": [
    "x_train_indices = get_indices(x_train, word_to_number, maxLen)\n",
    "y_train_oh = get_one_hot(y_train)\n",
    "print(y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2809/2809 [==============================] - 28s 10ms/step - loss: 1.5328 - categorical_accuracy: 0.2723\n",
      "Epoch 2/200\n",
      "2809/2809 [==============================] - 21s 8ms/step - loss: 1.5221 - categorical_accuracy: 0.2919\n",
      "Epoch 3/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.5202 - categorical_accuracy: 0.2880\n",
      "Epoch 4/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.5202 - categorical_accuracy: 0.2955\n",
      "Epoch 5/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.5142 - categorical_accuracy: 0.2955\n",
      "Epoch 6/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.5183 - categorical_accuracy: 0.2919\n",
      "Epoch 7/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.5148 - categorical_accuracy: 0.3008\n",
      "Epoch 8/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.5155 - categorical_accuracy: 0.2983\n",
      "Epoch 9/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.5124 - categorical_accuracy: 0.2941\n",
      "Epoch 10/200\n",
      "2809/2809 [==============================] - 24s 8ms/step - loss: 1.5135 - categorical_accuracy: 0.3022\n",
      "Epoch 11/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.5104 - categorical_accuracy: 0.3026\n",
      "Epoch 12/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.5120 - categorical_accuracy: 0.2983\n",
      "Epoch 13/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.5119 - categorical_accuracy: 0.2976\n",
      "Epoch 14/200\n",
      "2809/2809 [==============================] - 21s 8ms/step - loss: 1.5100 - categorical_accuracy: 0.2998\n",
      "Epoch 15/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.5092 - categorical_accuracy: 0.3012\n",
      "Epoch 16/200\n",
      "2809/2809 [==============================] - 26s 9ms/step - loss: 1.5094 - categorical_accuracy: 0.3111\n",
      "Epoch 17/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.5074 - categorical_accuracy: 0.3033\n",
      "Epoch 18/200\n",
      "2809/2809 [==============================] - 26s 9ms/step - loss: 1.5074 - categorical_accuracy: 0.3026\n",
      "Epoch 19/200\n",
      "2809/2809 [==============================] - 27s 10ms/step - loss: 1.5106 - categorical_accuracy: 0.3069\n",
      "Epoch 20/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.5097 - categorical_accuracy: 0.3069\n",
      "Epoch 21/200\n",
      "2809/2809 [==============================] - 26s 9ms/step - loss: 1.5089 - categorical_accuracy: 0.3033\n",
      "Epoch 22/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.5080 - categorical_accuracy: 0.3069\n",
      "Epoch 23/200\n",
      "2809/2809 [==============================] - 26s 9ms/step - loss: 1.5050 - categorical_accuracy: 0.3069\n",
      "Epoch 24/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.5060 - categorical_accuracy: 0.3054\n",
      "Epoch 25/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.5072 - categorical_accuracy: 0.3097\n",
      "Epoch 26/200\n",
      "2809/2809 [==============================] - 26s 9ms/step - loss: 1.5081 - categorical_accuracy: 0.3069\n",
      "Epoch 27/200\n",
      "2809/2809 [==============================] - 29s 10ms/step - loss: 1.5082 - categorical_accuracy: 0.3069\n",
      "Epoch 28/200\n",
      "2809/2809 [==============================] - 28s 10ms/step - loss: 1.5068 - categorical_accuracy: 0.3090\n",
      "Epoch 29/200\n",
      "2809/2809 [==============================] - 30s 11ms/step - loss: 1.5047 - categorical_accuracy: 0.3104\n",
      "Epoch 30/200\n",
      "2809/2809 [==============================] - 39s 14ms/step - loss: 1.5058 - categorical_accuracy: 0.3076\n",
      "Epoch 31/200\n",
      "2809/2809 [==============================] - 40s 14ms/step - loss: 1.5087 - categorical_accuracy: 0.3104\n",
      "Epoch 32/200\n",
      "2809/2809 [==============================] - 35s 12ms/step - loss: 1.5048 - categorical_accuracy: 0.3094\n",
      "Epoch 33/200\n",
      "2809/2809 [==============================] - 35s 12ms/step - loss: 1.5039 - categorical_accuracy: 0.3129\n",
      "Epoch 34/200\n",
      "2809/2809 [==============================] - 33s 12ms/step - loss: 1.5030 - categorical_accuracy: 0.3108\n",
      "Epoch 35/200\n",
      "2809/2809 [==============================] - 33s 12ms/step - loss: 1.5048 - categorical_accuracy: 0.3101\n",
      "Epoch 36/200\n",
      "2809/2809 [==============================] - 31s 11ms/step - loss: 1.5050 - categorical_accuracy: 0.3094\n",
      "Epoch 37/200\n",
      "2809/2809 [==============================] - 30s 11ms/step - loss: 1.5044 - categorical_accuracy: 0.3087\n",
      "Epoch 38/200\n",
      "2809/2809 [==============================] - 32s 11ms/step - loss: 1.5026 - categorical_accuracy: 0.3126\n",
      "Epoch 39/200\n",
      "2809/2809 [==============================] - 30s 11ms/step - loss: 1.5058 - categorical_accuracy: 0.3122\n",
      "Epoch 40/200\n",
      "2809/2809 [==============================] - 32s 11ms/step - loss: 1.5007 - categorical_accuracy: 0.3015\n",
      "Epoch 41/200\n",
      "2809/2809 [==============================] - 32s 11ms/step - loss: 1.5014 - categorical_accuracy: 0.3072\n",
      "Epoch 42/200\n",
      "2809/2809 [==============================] - 33s 12ms/step - loss: 1.5042 - categorical_accuracy: 0.3037\n",
      "Epoch 43/200\n",
      "2809/2809 [==============================] - 26s 9ms/step - loss: 1.5017 - categorical_accuracy: 0.3136\n",
      "Epoch 44/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.5048 - categorical_accuracy: 0.3097\n",
      "Epoch 45/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.5026 - categorical_accuracy: 0.3104\n",
      "Epoch 46/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.5026 - categorical_accuracy: 0.3108\n",
      "Epoch 47/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.5029 - categorical_accuracy: 0.3062\n",
      "Epoch 48/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.5049 - categorical_accuracy: 0.3069\n",
      "Epoch 49/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.5030 - categorical_accuracy: 0.3108\n",
      "Epoch 50/200\n",
      "2809/2809 [==============================] - 21s 7ms/step - loss: 1.5048 - categorical_accuracy: 0.3030\n",
      "Epoch 51/200\n",
      "2809/2809 [==============================] - 20s 7ms/step - loss: 1.5056 - categorical_accuracy: 0.3083\n",
      "Epoch 52/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.5021 - categorical_accuracy: 0.3104\n",
      "Epoch 53/200\n",
      "2809/2809 [==============================] - 27s 10ms/step - loss: 1.5026 - categorical_accuracy: 0.3126\n",
      "Epoch 54/200\n",
      "2809/2809 [==============================] - 28s 10ms/step - loss: 1.5016 - categorical_accuracy: 0.3062\n",
      "Epoch 55/200\n",
      "2809/2809 [==============================] - 26s 9ms/step - loss: 1.5031 - categorical_accuracy: 0.3101\n",
      "Epoch 56/200\n",
      "2809/2809 [==============================] - 30s 11ms/step - loss: 1.5015 - categorical_accuracy: 0.3115\n",
      "Epoch 57/200\n",
      "2809/2809 [==============================] - 30s 11ms/step - loss: 1.5018 - categorical_accuracy: 0.3069\n",
      "Epoch 58/200\n",
      "2809/2809 [==============================] - 29s 10ms/step - loss: 1.5020 - categorical_accuracy: 0.3133\n",
      "Epoch 59/200\n",
      "2809/2809 [==============================] - 28s 10ms/step - loss: 1.5024 - categorical_accuracy: 0.3108\n",
      "Epoch 60/200\n",
      "2809/2809 [==============================] - 28s 10ms/step - loss: 1.5038 - categorical_accuracy: 0.3087\n",
      "Epoch 61/200\n",
      "2809/2809 [==============================] - 33s 12ms/step - loss: 1.5008 - categorical_accuracy: 0.3108\n",
      "Epoch 62/200\n",
      "2809/2809 [==============================] - 29s 10ms/step - loss: 1.5001 - categorical_accuracy: 0.3115\n",
      "Epoch 63/200\n",
      "2809/2809 [==============================] - 29s 10ms/step - loss: 1.5006 - categorical_accuracy: 0.3129\n",
      "Epoch 64/200\n",
      "2809/2809 [==============================] - 34s 12ms/step - loss: 1.5016 - categorical_accuracy: 0.3087\n",
      "Epoch 65/200\n",
      "2809/2809 [==============================] - 38s 14ms/step - loss: 1.5010 - categorical_accuracy: 0.3094\n",
      "Epoch 66/200\n",
      "2809/2809 [==============================] - 40s 14ms/step - loss: 1.5016 - categorical_accuracy: 0.3133\n",
      "Epoch 67/200\n",
      "2809/2809 [==============================] - 54s 19ms/step - loss: 1.5033 - categorical_accuracy: 0.3044\n",
      "Epoch 68/200\n",
      "2809/2809 [==============================] - 63s 22ms/step - loss: 1.4984 - categorical_accuracy: 0.3108\n",
      "Epoch 69/200\n",
      "2809/2809 [==============================] - 48s 17ms/step - loss: 1.5024 - categorical_accuracy: 0.3076\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2809/2809 [==============================] - 45s 16ms/step - loss: 1.5009 - categorical_accuracy: 0.3072\n",
      "Epoch 71/200\n",
      "2809/2809 [==============================] - 48s 17ms/step - loss: 1.5006 - categorical_accuracy: 0.3111\n",
      "Epoch 72/200\n",
      "2809/2809 [==============================] - 48s 17ms/step - loss: 1.5025 - categorical_accuracy: 0.3079\n",
      "Epoch 73/200\n",
      "2809/2809 [==============================] - 49s 18ms/step - loss: 1.5007 - categorical_accuracy: 0.3186\n",
      "Epoch 74/200\n",
      "2809/2809 [==============================] - 49s 17ms/step - loss: 1.4997 - categorical_accuracy: 0.3133\n",
      "Epoch 75/200\n",
      "2809/2809 [==============================] - 44s 16ms/step - loss: 1.4983 - categorical_accuracy: 0.3108\n",
      "Epoch 76/200\n",
      "2809/2809 [==============================] - 35s 13ms/step - loss: 1.4991 - categorical_accuracy: 0.3176\n",
      "Epoch 77/200\n",
      "2809/2809 [==============================] - 35s 12ms/step - loss: 1.5013 - categorical_accuracy: 0.3126\n",
      "Epoch 78/200\n",
      "2809/2809 [==============================] - 34s 12ms/step - loss: 1.5001 - categorical_accuracy: 0.3143\n",
      "Epoch 79/200\n",
      "2809/2809 [==============================] - 34s 12ms/step - loss: 1.4994 - categorical_accuracy: 0.3090\n",
      "Epoch 80/200\n",
      "2809/2809 [==============================] - 29s 10ms/step - loss: 1.5005 - categorical_accuracy: 0.3126\n",
      "Epoch 81/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.4981 - categorical_accuracy: 0.3122\n",
      "Epoch 82/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.4998 - categorical_accuracy: 0.3111\n",
      "Epoch 83/200\n",
      "2809/2809 [==============================] - 28s 10ms/step - loss: 1.5015 - categorical_accuracy: 0.3094\n",
      "Epoch 84/200\n",
      "2809/2809 [==============================] - 27s 10ms/step - loss: 1.4996 - categorical_accuracy: 0.3083\n",
      "Epoch 85/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4996 - categorical_accuracy: 0.3122\n",
      "Epoch 86/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4970 - categorical_accuracy: 0.3122\n",
      "Epoch 87/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4973 - categorical_accuracy: 0.3097\n",
      "Epoch 88/200\n",
      "2809/2809 [==============================] - 21s 8ms/step - loss: 1.5000 - categorical_accuracy: 0.3083\n",
      "Epoch 89/200\n",
      "2809/2809 [==============================] - 21s 7ms/step - loss: 1.4963 - categorical_accuracy: 0.3136\n",
      "Epoch 90/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4974 - categorical_accuracy: 0.3111\n",
      "Epoch 91/200\n",
      "2809/2809 [==============================] - 21s 7ms/step - loss: 1.5011 - categorical_accuracy: 0.3101\n",
      "Epoch 92/200\n",
      "2809/2809 [==============================] - 20s 7ms/step - loss: 1.4992 - categorical_accuracy: 0.3090\n",
      "Epoch 93/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.5005 - categorical_accuracy: 0.3079\n",
      "Epoch 94/200\n",
      "2809/2809 [==============================] - 21s 7ms/step - loss: 1.4966 - categorical_accuracy: 0.3115\n",
      "Epoch 95/200\n",
      "2809/2809 [==============================] - 20s 7ms/step - loss: 1.4985 - categorical_accuracy: 0.3154\n",
      "Epoch 96/200\n",
      "2809/2809 [==============================] - 21s 7ms/step - loss: 1.5013 - categorical_accuracy: 0.3122\n",
      "Epoch 97/200\n",
      "2809/2809 [==============================] - 20s 7ms/step - loss: 1.5000 - categorical_accuracy: 0.3136\n",
      "Epoch 98/200\n",
      "2809/2809 [==============================] - 21s 7ms/step - loss: 1.4954 - categorical_accuracy: 0.3079\n",
      "Epoch 99/200\n",
      "2809/2809 [==============================] - 21s 7ms/step - loss: 1.5006 - categorical_accuracy: 0.3058\n",
      "Epoch 100/200\n",
      "2809/2809 [==============================] - 21s 8ms/step - loss: 1.4995 - categorical_accuracy: 0.3076\n",
      "Epoch 101/200\n",
      "2809/2809 [==============================] - 21s 7ms/step - loss: 1.4975 - categorical_accuracy: 0.3108\n",
      "Epoch 102/200\n",
      "2809/2809 [==============================] - 21s 7ms/step - loss: 1.4968 - categorical_accuracy: 0.3094\n",
      "Epoch 103/200\n",
      "2809/2809 [==============================] - 20s 7ms/step - loss: 1.5004 - categorical_accuracy: 0.3097\n",
      "Epoch 104/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4994 - categorical_accuracy: 0.3083\n",
      "Epoch 105/200\n",
      "2809/2809 [==============================] - 28s 10ms/step - loss: 1.4958 - categorical_accuracy: 0.3133\n",
      "Epoch 106/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.4969 - categorical_accuracy: 0.3108\n",
      "Epoch 107/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.4965 - categorical_accuracy: 0.3168\n",
      "Epoch 108/200\n",
      "2809/2809 [==============================] - 20s 7ms/step - loss: 1.4992 - categorical_accuracy: 0.3083\n",
      "Epoch 109/200\n",
      "2809/2809 [==============================] - 28s 10ms/step - loss: 1.4978 - categorical_accuracy: 0.3143\n",
      "Epoch 110/200\n",
      "2809/2809 [==============================] - 26s 9ms/step - loss: 1.4968 - categorical_accuracy: 0.3183\n",
      "Epoch 111/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4967 - categorical_accuracy: 0.3136\n",
      "Epoch 112/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4985 - categorical_accuracy: 0.3083\n",
      "Epoch 113/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4996 - categorical_accuracy: 0.3083\n",
      "Epoch 114/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4962 - categorical_accuracy: 0.3097\n",
      "Epoch 115/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4980 - categorical_accuracy: 0.3087\n",
      "Epoch 116/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4988 - categorical_accuracy: 0.3129\n",
      "Epoch 117/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4973 - categorical_accuracy: 0.3186\n",
      "Epoch 118/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4968 - categorical_accuracy: 0.3097\n",
      "Epoch 119/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4967 - categorical_accuracy: 0.3129\n",
      "Epoch 120/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4976 - categorical_accuracy: 0.3097\n",
      "Epoch 121/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4967 - categorical_accuracy: 0.3119\n",
      "Epoch 122/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4982 - categorical_accuracy: 0.3108\n",
      "Epoch 123/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4970 - categorical_accuracy: 0.3158\n",
      "Epoch 124/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4967 - categorical_accuracy: 0.3161\n",
      "Epoch 125/200\n",
      "2809/2809 [==============================] - 24s 8ms/step - loss: 1.4972 - categorical_accuracy: 0.3065\n",
      "Epoch 126/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4988 - categorical_accuracy: 0.3143\n",
      "Epoch 127/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4958 - categorical_accuracy: 0.3097\n",
      "Epoch 128/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4975 - categorical_accuracy: 0.3208\n",
      "Epoch 129/200\n",
      "2809/2809 [==============================] - 22s 8ms/step - loss: 1.4975 - categorical_accuracy: 0.3140\n",
      "Epoch 130/200\n",
      "2809/2809 [==============================] - 24s 8ms/step - loss: 1.4968 - categorical_accuracy: 0.3158\n",
      "Epoch 131/200\n",
      "2809/2809 [==============================] - 26s 9ms/step - loss: 1.4984 - categorical_accuracy: 0.3115\n",
      "Epoch 132/200\n",
      "2809/2809 [==============================] - 24s 8ms/step - loss: 1.4963 - categorical_accuracy: 0.3136\n",
      "Epoch 133/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4966 - categorical_accuracy: 0.3172\n",
      "Epoch 134/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4961 - categorical_accuracy: 0.3108\n",
      "Epoch 135/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4960 - categorical_accuracy: 0.3111\n",
      "Epoch 136/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4945 - categorical_accuracy: 0.3065\n",
      "Epoch 137/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.4970 - categorical_accuracy: 0.3158\n",
      "Epoch 138/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4944 - categorical_accuracy: 0.3151\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4955 - categorical_accuracy: 0.3133\n",
      "Epoch 140/200\n",
      "2809/2809 [==============================] - 26s 9ms/step - loss: 1.4966 - categorical_accuracy: 0.3122\n",
      "Epoch 141/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4981 - categorical_accuracy: 0.3161\n",
      "Epoch 142/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4962 - categorical_accuracy: 0.3208\n",
      "Epoch 143/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4980 - categorical_accuracy: 0.3136\n",
      "Epoch 144/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4958 - categorical_accuracy: 0.3154\n",
      "Epoch 145/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4975 - categorical_accuracy: 0.3151\n",
      "Epoch 146/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4970 - categorical_accuracy: 0.3094\n",
      "Epoch 147/200\n",
      "2809/2809 [==============================] - 24s 8ms/step - loss: 1.4988 - categorical_accuracy: 0.3147\n",
      "Epoch 148/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4944 - categorical_accuracy: 0.3158\n",
      "Epoch 149/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4957 - categorical_accuracy: 0.3179\n",
      "Epoch 150/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4975 - categorical_accuracy: 0.3151\n",
      "Epoch 151/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4971 - categorical_accuracy: 0.3119\n",
      "Epoch 152/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4958 - categorical_accuracy: 0.3176\n",
      "Epoch 153/200\n",
      "2809/2809 [==============================] - 24s 8ms/step - loss: 1.4970 - categorical_accuracy: 0.3108\n",
      "Epoch 154/200\n",
      "2809/2809 [==============================] - 24s 8ms/step - loss: 1.4953 - categorical_accuracy: 0.3129\n",
      "Epoch 155/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4972 - categorical_accuracy: 0.3129\n",
      "Epoch 156/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4957 - categorical_accuracy: 0.3172\n",
      "Epoch 157/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4951 - categorical_accuracy: 0.3136\n",
      "Epoch 158/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4957 - categorical_accuracy: 0.3108\n",
      "Epoch 159/200\n",
      "2809/2809 [==============================] - 24s 8ms/step - loss: 1.4985 - categorical_accuracy: 0.3158\n",
      "Epoch 160/200\n",
      "2809/2809 [==============================] - 24s 8ms/step - loss: 1.4969 - categorical_accuracy: 0.3158\n",
      "Epoch 161/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.4971 - categorical_accuracy: 0.3094\n",
      "Epoch 162/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4975 - categorical_accuracy: 0.3083\n",
      "Epoch 163/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.4952 - categorical_accuracy: 0.3101\n",
      "Epoch 164/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4956 - categorical_accuracy: 0.3151\n",
      "Epoch 165/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.4941 - categorical_accuracy: 0.3136\n",
      "Epoch 166/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4968 - categorical_accuracy: 0.3094\n",
      "Epoch 167/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4969 - categorical_accuracy: 0.3126\n",
      "Epoch 168/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4949 - categorical_accuracy: 0.3133\n",
      "Epoch 169/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4983 - categorical_accuracy: 0.3122\n",
      "Epoch 170/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4955 - categorical_accuracy: 0.3108\n",
      "Epoch 171/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4961 - categorical_accuracy: 0.3172\n",
      "Epoch 172/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4947 - categorical_accuracy: 0.3129\n",
      "Epoch 173/200\n",
      "2809/2809 [==============================] - 27s 10ms/step - loss: 1.4939 - categorical_accuracy: 0.3151\n",
      "Epoch 174/200\n",
      "2809/2809 [==============================] - 29s 10ms/step - loss: 1.4968 - categorical_accuracy: 0.3133\n",
      "Epoch 175/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4965 - categorical_accuracy: 0.3136\n",
      "Epoch 176/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4937 - categorical_accuracy: 0.3190\n",
      "Epoch 177/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4960 - categorical_accuracy: 0.3161\n",
      "Epoch 178/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4953 - categorical_accuracy: 0.3122\n",
      "Epoch 179/200\n",
      "2809/2809 [==============================] - 29s 10ms/step - loss: 1.4970 - categorical_accuracy: 0.3140\n",
      "Epoch 180/200\n",
      "2809/2809 [==============================] - 30s 11ms/step - loss: 1.4944 - categorical_accuracy: 0.3183\n",
      "Epoch 181/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4951 - categorical_accuracy: 0.3069\n",
      "Epoch 182/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4979 - categorical_accuracy: 0.3115\n",
      "Epoch 183/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4939 - categorical_accuracy: 0.3136\n",
      "Epoch 184/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4931 - categorical_accuracy: 0.3147\n",
      "Epoch 185/200\n",
      "2809/2809 [==============================] - 25s 9ms/step - loss: 1.4924 - categorical_accuracy: 0.3147\n",
      "Epoch 186/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4961 - categorical_accuracy: 0.3200\n",
      "Epoch 187/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4947 - categorical_accuracy: 0.3158\n",
      "Epoch 188/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4959 - categorical_accuracy: 0.3104\n",
      "Epoch 189/200\n",
      "2809/2809 [==============================] - 23s 8ms/step - loss: 1.4957 - categorical_accuracy: 0.3143\n",
      "Epoch 190/200\n",
      "2809/2809 [==============================] - 24s 9ms/step - loss: 1.4960 - categorical_accuracy: 0.3179\n",
      "Epoch 191/200\n",
      "2368/2809 [========================>.....] - ETA: 3s - loss: 1.4913 - categorical_accuracy: 0.3201"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_indices, y_train_oh, epochs = 200, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_indices = get_indices(x_test, word_to_number, max_len = maxLen)\n",
    "y_test_oh = get_one_hot(y_test)\n",
    "loss, acc = model.evaluate(x_test_indices, y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
