{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehak\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import sys\n",
    "#!{sys.executable} -m  pip install --upgrade tensorflow\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, GRU, Bidirectional, MaxPooling1D, Conv1D, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform, he_uniform, zeros\n",
    "from keras.optimizers import SGD, Adam, Adadelta\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_textFile(filePath):\n",
    "    ds_text = []\n",
    "    with open(filePath,'rb') as f:\n",
    "        for idx,ln in enumerate(f):\n",
    "            decoded=False\n",
    "            line=''\n",
    "            for cp in ('cp1252', 'cp850','utf-8','utf8'):\n",
    "                try:\n",
    "                    line = ln.decode(cp)\n",
    "                    decoded=True\n",
    "                    break\n",
    "                except UnicodeDecodeError:\n",
    "                    pass\n",
    "            if decoded:\n",
    "                ds_text.insert(idx, line.rstrip())\n",
    "    return ds_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pd.read_csv('Dataset/x_train.csv', sep=\",\", header=None,index_col = False)\n",
    "test_ds = pd.read_csv('Dataset/x_test.csv', sep=\",\", header=None,index_col = False)\n",
    "\n",
    "x_train = train_ds[0]\n",
    "y_train = train_ds[1]\n",
    "\n",
    "x_test = test_ds[0]\n",
    "y_test = test_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "maxLen = len(max(x_train, key=len).split())\n",
    "print(maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(y):\n",
    "    one_hot_temp_array = array(y)\n",
    "    one_hot_array = to_categorical(one_hot_temp_array)\n",
    "    return one_hot_array\n",
    "# invert encoding\n",
    "#inverted = argmax(encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load glove diembedding_dict = dict()\n",
    "embedding_dict = dict()\n",
    "glove_words = []\n",
    "#with open('Dataset/glove.twitter.27B/glove.twitter.27B.25d.txt','rb') as f:\n",
    "with open('Dataset/glove.6B.50d.txt','rb') as f:\n",
    "    for ln in f:\n",
    "        decoded=False\n",
    "        line=''\n",
    "        for cp in ('cp1252', 'cp850','utf-8','utf8'):\n",
    "            try:\n",
    "                line = ln.decode(cp)\n",
    "                decoded=True\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                pass\n",
    "        if decoded:\n",
    "            split = line.split(' ')\n",
    "\n",
    "            word = split[0]\n",
    "            glove_words.append(word)\n",
    "\n",
    "            features = split[1:]\n",
    "            features = np.array(\n",
    "                [float(val) for val in features]\n",
    "            )\n",
    "            embedding_dict[word] = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_word = glove_words\n",
    "word_to_number = dict((word,idx) for idx,word in enumerate(glove_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(input_x, word_to_number, max_len):\n",
    "    m = input_x.shape[0]\n",
    "    x_indices = np.zeros((m,max_len))\n",
    "\n",
    "    for i in range(m):\n",
    "        word_list =input_x.iloc[i][0].lower().split()\n",
    "        for idx,word in enumerate(word_list):\n",
    "            if (idx ==32):\n",
    "                continue\n",
    "            x_indices[i, idx] = word_to_number[word]\n",
    "    return x_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_layer(embedding_dict, word_to_number):\n",
    "    \n",
    "    emb_shape = embedding_dict[\"cucumber\"].shape[0]\n",
    "    total_words = len(word_to_number) + 1\n",
    "    \n",
    "    emb_matrix = np.zeros((total_words,emb_shape))\n",
    "    \n",
    "    for word,idx in word_to_number.items():\n",
    "        emb_matrix[idx, :] = embedding_dict[word]\n",
    "\n",
    "    embedding_layer = Embedding(total_words, emb_shape, trainable = True)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senti_model(input_shape,embedding_dict, word_to_number):\n",
    "    np.random.seed(1)\n",
    "    sentence_indices = Input(shape = input_shape, dtype = np.int32)\n",
    "    embedding_layer = get_embedding_layer(embedding_dict, word_to_number)\n",
    "    \n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    print(embeddings)\n",
    "    #,dropout=0.3,recurrent_dropout=0.3)\n",
    "    X = Dropout(0.4)(embeddings)\n",
    "    X = Bidirectional(GRU(64,return_sequences=True))(X)\n",
    "    #X = Dropout(0.4)(X)\n",
    "    X = Bidirectional(GRU(64,return_sequences=True))(X)\n",
    "    #X = Bidirectional(GRU(64,return_sequences=True))(X)\n",
    "    #X = Dropout(0.5)(X)\n",
    "    #X = Bidirectional(GRU(64,return_sequences=True))(X)\n",
    "    #X = Dropout(0.5)(X)\n",
    "    #X = BatchNormalization()\n",
    "    #X = BatchNormalization()(X)\n",
    "    X= Conv1D(50, 3, activation='relu',kernel_regularizer=regularizers.l2(0.02))(X)\n",
    "    X = MaxPooling1D(2)(X)\n",
    "    X = Dense(16, activation='elu')(X)\n",
    "    X = Dropout(0.4)(X)\n",
    "    #l_cov2 = Conv1D(32, 3, activation='relu',kernel_regularizer=regularizers.l2(0.01))(l_drop1)\n",
    "    #l_pool2 = MaxPooling1D(2)(l_cov2)\n",
    "    #l_drop2 = Dropout(0.3)(l_pool2)\n",
    "    #X = Flatten()(X)\n",
    "    X = Bidirectional(GRU(64,return_sequences=False))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dense(64, activation='elu')(X)\n",
    "    #X = Dense(64, activation='elu', name='fc-1')(X)\n",
    "    X = Dense(2, activation='softmax', name='fc')(X)\n",
    "\n",
    "\n",
    "    #X = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs = sentence_indices, outputs = X, name='stage-1')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_12/embedding_lookup/Identity:0\", shape=(?, 17, 50), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "embedding_12 (Embedding)     (None, 17, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 17, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 17, 128)           44160     \n",
      "_________________________________________________________________\n",
      "bidirectional_30 (Bidirectio (None, 17, 128)           74112     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 15, 50)            19250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7, 50)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 7, 16)             816       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_31 (Bidirectio (None, 128)               31104     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 20,178,390\n",
      "Trainable params: 20,178,134\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = senti_model((maxLen,), embedding_dict, word_to_number)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = Adam(lr=0.0001)\n",
    "adadelta = Adadelta(lr=1.00, rho=0.95, epsilon=None, decay=0.0)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adadelta, metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train_indices = get_indices(x_train, word_to_number, maxLen)\n",
    "y_train_oh = get_one_hot(y_train)\n",
    "print(y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "217/217 [==============================] - 21s 97ms/step - loss: 2.3033 - binary_accuracy: 0.4977\n",
      "Epoch 2/100\n",
      "217/217 [==============================] - 8s 35ms/step - loss: 2.0173 - binary_accuracy: 0.4885\n",
      "Epoch 3/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 1.8931 - binary_accuracy: 0.4654\n",
      "Epoch 4/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 1.7447 - binary_accuracy: 0.5253\n",
      "Epoch 5/100\n",
      "217/217 [==============================] - 7s 34ms/step - loss: 1.5059 - binary_accuracy: 0.6175\n",
      "Epoch 6/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 1.5619 - binary_accuracy: 0.4700\n",
      "Epoch 7/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 1.4212 - binary_accuracy: 0.4977\n",
      "Epoch 8/100\n",
      "217/217 [==============================] - 7s 34ms/step - loss: 1.3261 - binary_accuracy: 0.5484\n",
      "Epoch 9/100\n",
      "217/217 [==============================] - 7s 32ms/step - loss: 1.2682 - binary_accuracy: 0.5023\n",
      "Epoch 10/100\n",
      "217/217 [==============================] - 7s 34ms/step - loss: 1.1992 - binary_accuracy: 0.5207\n",
      "Epoch 11/100\n",
      "217/217 [==============================] - 7s 32ms/step - loss: 1.1031 - binary_accuracy: 0.5346\n",
      "Epoch 12/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 1.1016 - binary_accuracy: 0.4240\n",
      "Epoch 13/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 1.0044 - binary_accuracy: 0.5253\n",
      "Epoch 14/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.9847 - binary_accuracy: 0.4516\n",
      "Epoch 15/100\n",
      "217/217 [==============================] - 7s 32ms/step - loss: 0.9348 - binary_accuracy: 0.5253\n",
      "Epoch 16/100\n",
      "217/217 [==============================] - 7s 32ms/step - loss: 0.8780 - binary_accuracy: 0.5253\n",
      "Epoch 17/100\n",
      "217/217 [==============================] - 8s 35ms/step - loss: 0.8723 - binary_accuracy: 0.5300\n",
      "Epoch 18/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.8741 - binary_accuracy: 0.3825\n",
      "Epoch 19/100\n",
      "217/217 [==============================] - 8s 35ms/step - loss: 0.7992 - binary_accuracy: 0.5115\n",
      "Epoch 20/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.7883 - binary_accuracy: 0.4562\n",
      "Epoch 21/100\n",
      "217/217 [==============================] - 8s 35ms/step - loss: 0.7494 - binary_accuracy: 0.5576\n",
      "Epoch 22/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.7716 - binary_accuracy: 0.5161\n",
      "Epoch 23/100\n",
      "217/217 [==============================] - 7s 34ms/step - loss: 0.7574 - binary_accuracy: 0.4470\n",
      "Epoch 24/100\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.7391 - binary_accuracy: 0.5069\n",
      "Epoch 25/100\n",
      "217/217 [==============================] - 7s 34ms/step - loss: 0.7459 - binary_accuracy: 0.4977\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-3b66c070d84f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train_indices, y_train_oh, epochs = 100, batch_size = 16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 3s 20ms/step\n",
      "\n",
      "Test accuracy =  0.741258742926004\n"
     ]
    }
   ],
   "source": [
    "x_test_indices = get_indices(x_test, word_to_number, max_len = maxLen)\n",
    "y_test_oh = get_one_hot(y_test)\n",
    "loss, acc = model.evaluate(x_test_indices, y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(value):\n",
    "    unique_labels = [\"negative\",\"positive\"]\n",
    "    return unique_labels[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected positive prediction: negative thank much gloria series sweet thoughtful you made day joyful i love too of\n",
      "Expected positive prediction: negative thanks making mass fr vallely respectful meaningful joyful\n",
      "Expected positive prediction: negative currently listening amp podcasts can guys please move yvr hilarious mission\n",
      "Expected positive prediction: negative well done ladies a great award amazing team a delight present award you\n",
      "Expected positive prediction: negative use smile change world series let world change smile quote love fun\n",
      "Expected positive prediction: negative a a a whole time watching lost glasses it hilarious\n",
      "Expected positive prediction: negative i simple human really loves like truly madly deeply rejoicing existence class queen dom\n",
      "Expected positive prediction: negative ill there cant wait\n",
      "Expected positive prediction: negative series meant be happy happy\n",
      "Expected positive prediction: negative thought gets day thought smile never fails making smile a\n",
      "Expected positive prediction: negative second day job already got dollar tip dude whose constantly twitching eye cheering\n",
      "Expected positive prediction: negative series elated sid espinosa ready inspire innovative students\n",
      "Expected positive prediction: negative gunny smith like today i happy alive blessed rejoice\n",
      "Expected positive prediction: negative thank you happy birthday well\n",
      "Expected positive prediction: negative a smile brightens day day everyone around you remember smile free\n",
      "Expected positive prediction: negative series watching joyful noise time cuz i love movie\n",
      "Expected positive prediction: negative food gets delivered cheering happy\n",
      "Expected positive prediction: negative getting comedic relief w season premiere modern family just series needs hilarious\n",
      "Expected positive prediction: negative good morning love happy first day fall series make awesome anna bailey laughter smile\n",
      "Expected positive prediction: negative series cute truelove hilarious beautiful amp graceful never heard explicit s spoken elegance mingo\n",
      "Expected positive prediction: negative thank disney themed episode letting discover amazing series hilarious\n",
      "Expected positive prediction: negative series fantastic i bet super exhilarating of\n",
      "Expected positive prediction: negative series dear evening absolute hilarity i do not think i laughed much long time a\n",
      "Expected positive prediction: negative i love laugh share laughter way share joy\n",
      "Expected positive prediction: negative today i reached subscribers youtube you there happy good day thankful\n",
      "Expected positive prediction: negative be positive cheerful grateful expectant success leadership\n",
      "Expected positive prediction: negative i would like congratulate people saudi arabia happy joyous national day may great time\n",
      "Expected positive prediction: negative when wake dream laughing something stupid makes laugh hilarious\n",
      "Expected positive prediction: negative mate thing i get excited profession mad a client said opened bowels series rejoicing\n",
      "Expected positive prediction: negative wishing happy birthday awesome dancer ruthann series hope day magical series happy\n",
      "Expected positive prediction: negative series first day of fall series happy sipping pumpkin spice flavored coffee smiling happy fall everyone writing\n",
      "Expected positive prediction: negative love much smile of\n",
      "Expected positive prediction: negative i feel blessed work family i nanny of nothing love amp appreciation makes smile\n",
      "Expected positive prediction: negative today first time math professor let us live early class time min happy wednesday\n",
      "Expected positive prediction: negative always indeed wonderful experience flying guys today best in business happy\n",
      "Expected positive prediction: negative something cool breezy fall days\n",
      "Expected positive prediction: negative found thin mints freezer clean could not elated\n"
     ]
    }
   ],
   "source": [
    "C = 4\n",
    "y_test_array = y_test.values\n",
    "y_test_oh = np.eye(C)[y_test_array.reshape(-1)]\n",
    "X_test_indices = get_indices(x_test, word_to_number, maxLen)\n",
    "pred = model.predict(x_test_indices)\n",
    "for i in range(len(x_test)):\n",
    "    x = x_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != y_test_array[i]):\n",
    "        print('Expected '+ get_emotion(y_test_array[i]) + ' prediction: '+ get_emotion(num) + ' ' + x_test[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
